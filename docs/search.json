[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "",
    "text": "The State of the Nation Address (SONA) delivered by the President of South Africa is a significant annual event. It serves as a platform for the nation’s leader to engage with citizens, government officials, and international observers. This address offers a pivotal opportunity for the President to assess the nation’s current state, articulate government priorities, and lay out policies and plans for the future. It represents a moment that encapsulates the nation’s aspirations in politics, society, and the economy.\nIn the context of this research project, we have access to a dataset comprising a total of 36 text files, each representing speeches delivered by six different presidents during the period from 1994 to 2023. The dataset includes 7 speeches from Nelson Mandela, 10 from Mbeki, 1 from Motlanthe, 1 from Ramaphosa, 10 from Zuma, and 1 from de Klerk. The examination reveals an imbalance within the data, highlighting the importance of implementing a stratified sampling approach during the division of the data into training and test sets. This approach involves stratifying the samples based on the target variable (president) to guarantee that the selected data accurately mirrors the characteristics of the original dataset.\nThe primary objective of this analysis is to utilize the text data alongside a feed forward neural network to predict which of the six presidents delivered a specific speech. The outcomes generated by the neural network will be compared with those of other predictive models, such as a Naive Bayes classifier and a Support Vector Machine. This comparative analysis aims to enhance our understanding of the most effective approach for attributing speeches to their respective presidents based on the text content."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#tokenization",
    "href": "index.html#tokenization",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Tokenization",
    "text": "Tokenization\nThis is a process of breaking down a text into individual words or tokens. Each word or punctuation mark is considered a token. For instance, the sentence “The time will come when our nation will honour” would be tokenized into (““The”, “time”, “will”, “come”, “when”, “our”,“nation”,“will”,“honour”).\n\nStemming\nThis is text normalization technique where words are reduced to their root or base form. This helps to group words with the same root together. For example in the data the word “thoughts” is stemmed to “thought”, and “memory” is stemmed to “memori”.\n\n\nRemoving stop words\nRemoving stop words is a process of eliminating common words like “the,” “and,” “is,” which don’t carry much meaning in text analysis and may skew our results if included in the analysis. For example, in our data the token (“the” “time” “will” “come” “when” “our” “nation” “will” “honour” “the” “memory”), will be reduced to (“time” “come” “nation” “honour” “memory” “sons” “daughters” “mothers”).\nTo proces the data using the techniques detailed above, the data corpus object using the quanteda package. A corpus is a collection of sentences. The corpus object was then converted into tokens , removing punctuation. The tokens were converted into a “Document-Feature Matrix” (dfm) which is a crucial component for analyzing and modeling text data. In this process the tokens are converted into a lowercase, stemmed and stop words are removed.\nThe output below shows that the dfm object has 6 871 documents and 8 470 features (total number of unique words). The dfm matrix contains a total 113 584 word, but only 8 471 words are unique. However, the data is 99.81% sparse, this means that 99.86% of the values in the matrix are 0. This is a very high number. This tells us that only 0.19% of the 6 871 sentences(documents) contains all the 8 470 words.\n\n\n\nDocument-feature matrix of: 6,877 documents, 8,470 features (99.81% sparse) and 2 docvars.\n       features\ndocs    time come nation honour memori son daughter mother father youth\n  text1    1    1      1      1      1   1        1      1      1     1\n  text2    0    1      0      0      0   0        0      0      0     0\n  text3    0    0      0      0      0   0        0      0      0     0\n  text4    0    0      0      0      0   0        0      0      0     0\n  text5    0    0      0      0      0   0        0      0      0     0\n  text6    0    0      0      0      0   0        0      0      0     0\n[ reached max_ndoc ... 6,871 more documents, reached max_nfeat ... 8,460 more features ]"
  },
  {
    "objectID": "index.html#model-1-bag-of-words",
    "href": "index.html#model-1-bag-of-words",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 1: Bag-of-Words",
    "text": "Model 1: Bag-of-Words\nThe input data for this model represent individual features, and the observations denote the frequency of each word’s appearance within each sentence spoken by each president (the target). The model is trained on a reduced dataset, including only those features that occur in at least 200 sentences. This results in a feature space consisting of 74 unique words and a dataset of 6,877 observations. The data is split into 3 datasets, the training set (60%), validation set (20%) and the test set (20%).\nConsidering that the data employed in model 1 encompasses the absolute counts of word occurrences within each observation, the training dataset is subjected to standardization. This process aims to mitigate the undue impact of words with a broader range of values. For instance, the word “nation” appears in sentences ranging from 0 to 18 times, whereas “well” spans from 0 to 2 uses. The validation and test datasets are likewise standardized using the means and standard deviations obtained from the training data."
  },
  {
    "objectID": "index.html#model-2-weighted-frequency-count",
    "href": "index.html#model-2-weighted-frequency-count",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 2: Weighted Frequency Count",
    "text": "Model 2: Weighted Frequency Count\n\ntoks_tfid &lt;- dfm_tfidf(toks2)\n\n#get new df"
  },
  {
    "objectID": "index.html#model-1-bag-of-words-frequency-of-words-count",
    "href": "index.html#model-1-bag-of-words-frequency-of-words-count",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 1: Bag-of-Words: Frequency of words count",
    "text": "Model 1: Bag-of-Words: Frequency of words count\nThe input data for this model represent individual features, and the observations denote the frequency of each word’s appearance within each sentence spoken by each president (the target). The model is trained on a reduced dataset, including only those features that occur in at least 200 sentences. This results in a feature space consisting of 74 unique words and a dataset of 6,877 observations. The data is split into 3 datasets, the training set (60%), validation set (20%) and the test set (20%).\nConsidering that the data employed in model 1 encompasses the absolute counts of word occurrences within each observation, the training dataset is subjected to standardization. This process aims to mitigate the undue impact of words with a broader range of values. For instance, the word “nation” appears in sentences ranging from 0 to 18 times, whereas “well” spans from 0 to 2 uses. The validation and test datasets are likewise standardized using the means and standard deviations obtained from the training data. The target variable is converted into a vector of 1 and 0 using a one hot encoding technique which transforms the categorical labels into a binary matrix format.\n\nFeed Forward Neural Network\nThe first model fitted is a neural network designed for a multi-class classification problem with 6 classes. The ReLU activation function is used in the hidden layers to introduce non-linearity, and the softmax activation function is used in the output layer to produce class probabilities.\nThe categorical cross-entropy loss is chosen as an loss function for multi-class classification tasks, and the Adam optimizer with a learning rate of 0.01 is used to update the model’s weights during training.\nThe model underwent 50 training epochs with batches of 32 samples each. The model fit resulted in a validation accuracy of just 37.84%, furthermore the neural network assigned non of the predictions to De Klerk.\nMultinomial Logistic Regression\nFor the logistic regression, an output layer using activation = “softmax” was chosen as it is a appropriate for multi-class classification. It will provide class probabilities for each of the 6 classes. The loss function was also set to “categorical_crossentropy”, which is the standard choice for multi-class problems.\nWith a logistic regression the model validation accuracy is 43.72%, this is a 588 basis points uplift in performance compared to the neural network. The logistic regression model assigned none of the predictions to Motlhante and De Klerk.\nSupport Vector Machine\nA support vector machine (SVM) model was trained with a radial kernel, which is a suitable choice when there’s uncertainty about the data’s underlying structure. The radial kernel is adept at capturing complex decision boundaries, which is especially important in multi-class classification scenarios where linear boundaries may not suffice. A low gamma value (0.1) was selected to create a more lenient decision boundary, a valuable approach for multi-class datasets with potential class overlap. To mitigate overfitting, the cost parameter was set to a high value of 10, increasing the penalty for misclassification. SVM can effectively handle the categorical target variable in its original form, eliminating the need for one-hot encoding to transform the target into a binary matrix.\nThe model’s validation accuracy is 39 %. This is a 79 basis point uplift from the neural network, but lower that the results obtained using a logistic regression.\n\nFor the BoW frequency count text processing technique, the logistic regression yields superior results. Table 4 shows that the algorithm is unable to assign any prediction to De Klerk and Motlanthe. The model performs the best when predicted words by President Zuma. The president has 417 words in the corpus, and the model accurately predicted 56% (test accuracy) . President Ramaphosa has 377 words in the corpus, and the model accurately predicted 50% of his words. The model is ineffective at predicting words said by President Mandela. The president has 203 words in the corpus, however the model only accuracy predicts 21% of those words.\n\n\n\nTable 4: Actual (row) vs Predicted (column) Results by logistic Regression on BoW\n\n\n\ndeKlerk\nMandela\nMbeki\nMotlanthe\nRamaphosa\nZuma\nTotal\n\n\n\n\ndeKlerk\n0\n2\n5\n0\n5\n3\n15\n\n\nMandela\n0\n42\n54\n0\n48\n59\n203\n\n\nMbeki\n0\n32\n138\n0\n62\n91\n323\n\n\nMotlanthe\n0\n6\n12\n0\n10\n14\n42\n\n\nRamaphosa\n0\n9\n25\n0\n190\n153\n377\n\n\nZuma\n0\n19\n48\n0\n118\n232\n417"
  },
  {
    "objectID": "index.html#model-2-bag-of-words-one-hot-encoding",
    "href": "index.html#model-2-bag-of-words-one-hot-encoding",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 2: Bag-of-Words: (One hot encoding)",
    "text": "Model 2: Bag-of-Words: (One hot encoding)\nFor this model, the features are transformed into\n\n# Load the required library\n# library(e1071)\n# \n# svm1 &lt;- svm(president~., data= df[inds$train,] , \n#           method=\"C-classification\", kernal=\"radial\", \n#           gamma=0.1, cost=10)\n# \n# y_pred = predict(svm1, newdata = df[inds$valid,])\n# confusion_table3 = table(df[inds$valid,]$president, y_pred)\n# \n# accuracy = (cm[1,1] + cm[2,2]+cm[3,3]+\n#                 cm[4,4]+cm[5,5]+cm[6,6]) / nrow(test_fold)"
  },
  {
    "objectID": "index.html#model-3-tf-idf-weighted-frequency-count",
    "href": "index.html#model-3-tf-idf-weighted-frequency-count",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 3: TF-IDF: Weighted Frequency Count:",
    "text": "Model 3: TF-IDF: Weighted Frequency Count:\n\ntoks_tfid &lt;- dfm_tfidf(toks2)\n\n#get new df\n\n\n#dfm to keras output\n# library(\"keras\")\n# txt &lt;- c(d1 = \"a a b b b c\", d2 = \"a b c c c c\")\n# tokenizer &lt;- text_tokenizer(num_words = 4) %&gt;%\n#     fit_text_tokenizer(txt)\n# \n# dfm_to_kerasmatrix &lt;- function(x) {\n#     mat &lt;- dfm_sort(x, margin = \"features\") %&gt;%\n#         as.matrix()\n#     dimnames(mat) &lt;- NULL\n#     cbind(rep(0, nrow(mat)), mat)\n# }\n#     \n# identical(\n#     texts_to_matrix(tokenizer, txt, mode = \"count\"),\n#     dfm_to_kerasmatrix(dfm(txt))\n# )"
  },
  {
    "objectID": "index.html#model-2-tf-idf-weighted-frequency-count",
    "href": "index.html#model-2-tf-idf-weighted-frequency-count",
    "title": "Assignment 1: Predict the President (Neural Networks)",
    "section": "Model 2: TF-IDF: Weighted Frequency Count",
    "text": "Model 2: TF-IDF: Weighted Frequency Count\nTF-IDF, or Term Frequency-Inverse Document Frequency, is a numerical representation that combines two key components. It involves a log transformation of the word frequency count within a document, and it also accounts for the word’s significance across the entire corpus.\nFor example, consider the sentence “The certainties that come with age tell me that,” which consists of a total of 9 words. The word “that” appears 2 times in this sentence. To calculate the Term Frequency (TF) for “that” in this sentence, you take the ratio of its frequency to the total words, resulting in (2/9).\nHowever, it’s equally important to consider how often the word “that” appears across all sentences in the corpus. If, for instance, it appears in only 4 out of 9 sentences, the Inverse Document Frequency (IDF) is determined as log(9/4). Consequently, the TF-IDF score for the word “that” in this sentence is calculated as (2/9) * log(9/4), yielding a value of 1.078.\nTo compute TF-IDF for the entire corpus, the process can be efficiently executed using the quanteda package. This package takes the original Document-Feature Matrix (DFM) object, containing 6,871 documents and 8,470 features, and applies the necessary log transformation to derive the TF-IDF values for the entire corpus. Words with low TF-IDF score are commonly used words in the corpus. While words with a high TF-IDF score denote the significance of the word in within that document.\n\nTable 5 shows that the most unique and significant word across the entire corpus is compatriot, followed by honour.\n\n\n\nTable 5: Ten 10 unique or highly significant words across the entire collection SONA corpus\n\n\ncompatriot\nhonour\nspeaker\nthank\nmember\nsouth\nyear\ngovern\nafrican\nmadam\n\n\n\n\n138.8761\n77.36564\n60.67334\n58.79029\n58.67654\n58.50207\n54.93527\n52.70048\n52.17351\n50.54257\n\n\n\n\n\n\n\n\nThe feature space of the corpus was reduces by keeping only features with a total TD-IDF score of at least 10 across all documents. This resulted in a drop of feature space from 8470 to 285.\nFeed Forward Neural Network\nThe data preprocessing steps applied to the Bag of Words (BoW) model were also utilized for the TF-IDF model. Additionally, the hyperparameters used for the neural network in the TF-IDF model remained the same, with the sole exception being that the first hidden layer now consists of 100 neurons.\nThe test accuracy of the model was 45.32%\nLogistic Regression and SVM\nThe Logistic Regression and Support Vector Machine (SVM) models were both trained with identical hyperparameters as those used for the Bag of Words (BoW) model.\nThe test accuracy of the logistic regression is 47.28% and 30.28% for SVM.\nComparing BoW Model and TF-IDF Model\nJust like with the Bag of Words (BoW) algorithm, logistic regression outperforms SVM and Neural Network in predicting presidential speeches when utilizing the log transformation of word frequency.\n\n\n\nTable 6: Comparing performance of models fitted using BoW and TD-IDF text processing techniques\n\n\n\nModel\nNeural Network\nLogistic Regression\nSupport Vector Machine\n\n\n\n\n1\nBoW:frequency count\n37.84\n43.72\n38.63\n\n\n2\nTF-TDF\n45.32\n47.28\n30.28\n\n\n\n\n\n\n\nTable 6 shows that the TD-IDF model is generally superior in performance to the Bag of Words (BoW) model across various aspects, but there is an exception for the Support Vector Machine (SVM). This discrepancy can be attributed to several factors. The choice of hyperparameters may not have been optimized for the TD-IDF model, leading to suboptimal results. It’s also possible that certain characteristics of the TD-IDF data do not align well with the inherent assumptions of the SVM algorithm.\nUnlike the logistic regression model fitted on BoW data, the logistic regression fitted on TD-IDF corpus was able to assign predictions to De Klerk and Motlanthe. Out of the 15 distinct words spoken by De Klerk, the model was able to predict 5 of the words correctly.This suggests that the TD-IDF model better captures the nuances of De Klerk’s speech patterns. Furthermore the test accuracy of words spoken by Ramaphosa increased to 55% compared to 50% using BoW model. The model can is able to identify his distinct communication style. The model also improved it’s ability to predict speech made my Mandela to 32% compared to 21% using BoW. TD-IDF model captures the unique language characteristics of Mandela more effectively.\n\n\n\nTable 7: Actual (row) vs Predicted (column) Results by logistic Regression on TD-IDF data\n\n\n\ndeKlerk\nMandela\nMbeki\nMotlanthe\nRamaphosa\nZuma\nTotal\n\n\n\n\ndeKlerk\n5\n2\n4\n0\n1\n3\n15\n\n\nMandela\n1\n65\n57\n0\n41\n39\n203\n\n\nMbeki\n0\n43\n144\n1\n62\n73\n323\n\n\nMotlanthe\n0\n12\n12\n1\n7\n10\n42\n\n\nRamaphosa\n1\n25\n43\n2\n207\n99\n377\n\n\nZuma\n1\n25\n58\n0\n104\n229\n417"
  }
]